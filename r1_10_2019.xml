<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
   <channel>
      <title>CoMeT</title>
      <description>Collaborative Management of Talks: A social web system for research communities</description>
      <link>http://halley.exp.sis.pitt.edu/comet/</link>
      <item>
         <title><![CDATA[Artificial Intelligence Healthcare - From Prevention & Diagnostics to Treatments (AI-PDT)]]></title>
         <pubDate>Monday, Sep 30 12:19 PM -0400</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=17958</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;NIH Artificial Intelligence Interest Group (AIIG), Office of Intramural Research and NIH AI Working Group for Autonomous Therapeutics (AIAT)<br/><b>Date:</b>&nbsp;Tuesday, Oct 01 on 9:00 AM - 5:30 PM<br/><b>Location:</b>&nbsp;Online - Webinar<br/><b>Detail:<b><p>We will explore how we can cooperate to apply AI to enhance, and revolutionize, healthcare. Our goals will include, but not be limited to, the following:<br />
<br />
1. To strengthen and expand NIH?s innovation ecosystem by engaging a broad range of researchers, practitioners, and other professionals interested in artificial intelligence healthcare across the nation?s academic and industrial bases.<br />
2. To inform stakeholders of NIH?s vision and priorities for AI, in the context of smart healthcare, to better enable collaboration and transition of technologies.<br />
3. To inspire the technical research community to seek research and development partnerships with the Agency by sharing NIH?s record of innovative achievements.<br />
4. To establish an AI Healthcare Task Force with Trans-NIH and Trans-Agency collaboration.</p>]]></content:encoded>
         <description><![CDATA[Speaker:�NIH Artificial Intelligence Interest Group (AIIG), Office of Intramural Research and NIH AI Working Group for Autonomous Therapeutics (AIAT)Date:�Tuesday, Oct 01 on 9:00 AM - 5:30 PMLocation:�Online - WebinarDetail:We will explore how we can cooperate to apply AI to enhance, and revolutionize, healthcare. Our goals will include, but not be limited to, the following: 1. To strengthen and expand NIH?s innovation ecosystem by engaging a broad range of researchers, practitioners, and other professionals interested in artificial intelligence healthcare across the nation?s academic and industrial bases. 2. To inform stakeholders of NIH?s vision and priorities for AI, in the context of smart healthcare, to better enable collaboration and transition of technologies. 3. To inspire the technical research community to seek research and development partnerships with the Agency by sharing NIH?s record of innovative achievements. 4. To establish an AI Healthcare Task Force with Trans-NIH and Trans-Agency collaboration.]]></description>
         <author>comet.paws</author>
      </item>
      <item>
         <title><![CDATA[Overcoming Mode Collapse and the Curse of Dimensionality]]></title>
         <pubDate>Friday, Sep 27 10:29 AM -0400</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=18074</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;Ke Li<br/><b>Date:</b>&nbsp;Tuesday, Oct 01 on 10:30 AM - 11:30 AM<br/><b>Location:</b>&nbsp;3305 Newell-Simon Hall<br/><b>Detail:<b><p><strong>Abstract:</strong></p>

<p>&nbsp;</p>

<p>In this talk, I will present our work on overcoming two long-standing problems in machine learning and algorithms:</p>

<p>&nbsp;</p>

<p>1. Mode collapse in generative adversarial nets (GANs)</p>

<p>&nbsp;</p>

<p>Generative adversarial nets (GANs) are perhaps the most popular class of generative models in use today. Unfortunately, they suffer from the well-documented problem of mode collapse, which the many successive variants of GANs have failed to overcome. I will illustrate why mode collapse happens fundamentally and show a simple way to overcome it, which is the basis of a new method known as Implicit Maximum Likelihood Estimation (IMLE).</p>

<p>2. Curse of dimensionality in exact nearest neighbour search</p>

<p>&nbsp;</p>

<p>Efficient algorithms for exact nearest neighbour search developed over the past 40 years do not work in high (intrinsic) dimensions, due to the curse of dimensionality. It turns out that this problem is not insurmountable - I will explain how the curse of dimensionality arises and show a simple way to overcome it, which is the gives rise to a new family of algorithms known as Dynamic Continuous Indexing (DCI).</p>

<p>&nbsp;</p>

<p><strong>Bio:</strong></p>

<p>&nbsp;</p>

<p>Ke Li is a recent Ph.D. graduate from UC Berkeley, where he was advised by Prof. Jitendra Malik, and will join Google as a Research Scientist and the Institute for Advanced Study (IAS) as a Member hosted by Prof. Sanjeev Arora. He is interested in a broad range of topics in machine learning, computer vision, NLP and algorithms and has worked on generative modelling, nearest neighbour search and Learning to Optimize. He is particularly passionate about tackling long-standing fundamental problems that cannot be tackled with a straightforward application of conventional techniques. He received his Hon. B.Sc. in Computer Science from the University of Toronto in 2014.</p>]]></content:encoded>
         <description><![CDATA[Speaker:�Ke LiDate:�Tuesday, Oct 01 on 10:30 AM - 11:30 AMLocation:�3305 Newell-Simon HallDetail:Abstract: � In this talk, I will present our work on overcoming two long-standing problems in machine learning and algorithms: � 1. Mode collapse in generative adversarial nets (GANs) � Generative adversarial nets (GANs) are perhaps the most popular class of generative models in use today. Unfortunately, they suffer from the well-documented problem of mode collapse, which the many successive variants of GANs have failed to overcome. I will illustrate why mode collapse happens fundamentally and show a simple way to overcome it, which is the basis of a new method known as Implicit Maximum Likelihood Estimation (IMLE). 2. Curse of dimensionality in exact nearest neighbour search � Efficient algorithms for exact nearest neighbour search developed over the past 40 years do not work in high (intrinsic) dimensions, due to the curse of dimensionality. It turns out that this problem is not insurmountable - I will explain how the curse of dimensionality arises and show a simple way to overcome it, which is the gives rise to a new family of algorithms known as Dynamic Continuous Indexing (DCI). � Bio: � Ke Li is a recent Ph.D. graduate from UC Berkeley, where he was advised by Prof. Jitendra Malik, and will join Google as a Research Scientist and the Institute for Advanced Study (IAS) as a Member hosted by Prof. Sanjeev Arora. He is interested in a broad range of topics in machine learning, computer vision, NLP and algorithms and has worked on generative modelling, nearest neighbour search and Learning to Optimize. He is particularly passionate about tackling long-standing fundamental problems that cannot be tackled with a straightforward application of conventional techniques. He received his Hon. B.Sc. in Computer Science from the University of Toronto in 2014.]]></description>
         <author>OliverHao</author>
      </item>
      <item>
         <title><![CDATA[Better Music Representation Learning Using Inductive Bias: Mind vs. Machine]]></title>
         <pubDate>Thursday, Sep 26 6:59 PM -0400</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=18082</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;GUS Guangyu XIA<br/><b>Date:</b>&nbsp;Tuesday, Oct 01 on 12:00 PM - 1:00 PM<br/><b>Location:</b>&nbsp;NSH 3305, CMU<br/><b>Detail:<b><p><strong>Abstract</strong>: Gus works on music AI systems for intimate human-computer interaction and co-creation. In this talk, he will present two recent prototype systems: the multimodal flute tutor and the interpretable deep music composer. The former is a hyper instrument which guides human motion and makes music learning more efficient and enjoyable. The latter is a general framework for learning disentangled representation. We will see that for both human learning and machine learning, inductive bias plays an important role. At the end of the talk, Gus will show his vision on merging these two efforts for new music experiences.</p>

<p><strong>Bio</strong>: Gus is an Assistant Professor in Computer Science at NYU Shanghai. He received his Ph.D. in the Machine Learning Department at Carnegie Mellon University in 2016 and was a Neukom Fellow at Dartmouth from 2016 to 2017. Gus is also a professional DI and XIAO (Chinese flute and vertical flute) player.</p>]]></content:encoded>
         <description><![CDATA[Speaker:�GUS Guangyu XIADate:�Tuesday, Oct 01 on 12:00 PM - 1:00 PMLocation:�NSH 3305, CMUDetail:Abstract: Gus works on music AI systems for intimate human-computer interaction and co-creation. In this talk, he will present two recent prototype systems: the multimodal flute tutor and the interpretable deep music composer. The former is a hyper instrument which guides human motion and makes music learning more efficient and enjoyable. The latter is a general framework for learning disentangled representation. We will see that for both human learning and machine learning, inductive bias plays an important role. At the end of the talk, Gus will show his vision on merging these two efforts for new music experiences. Bio: Gus is an Assistant Professor in Computer Science at NYU Shanghai. He received his Ph.D. in the Machine Learning Department at Carnegie Mellon University in 2016 and was a Neukom Fellow at Dartmouth from 2016 to 2017. Gus is also a professional DI and XIAO (Chinese flute and vertical flute) player.]]></description>
         <author>bmaneesh</author>
      </item>
      <item>
         <title><![CDATA[The Ethical Algorithm]]></title>
         <pubDate>Friday, Oct 04 1:27 PM -0400</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=18129</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;Aaron Roth<br/><b>Date:</b>&nbsp;Friday, Oct 04 on 4:30 PM - 6:00 PM<br/><b>Location:</b>&nbsp;Gates Hillman Centers, Rashid Auditorium 4401<br/><b>Detail:<b><p>Many recent mainstream media articles and popular books have raised alarms over anti-social algorithmic behavior, especially when driven by machine learning. The concerns include leaks of sensitive personal data by predictive models, algorithmic discrimination as a side-effect of machine learning, and inscrutable decisions made by complex models. While standard and legitimate responses to these phenomena include calls for better laws and regulations, researchers in machine learning, statistics and related areas are also working on designing better-behaved algorithms. An explosion of recent research in areas such as differential privacy, algorithmic fairness and algorithmic game theory is forging a new science of socially aware algorithm design. I will survey these developments and attempt to place them in a broader societal context --- and give a taste for what this work is like via a technical anecdote from our own recent research. This talk is based on the forthcoming book <strong>The Ethical Algorithm</strong>, co-authored with Michael Kearns, and available for pre-order now.</p>

<p>&nbsp;</p>

<p>About the <a href="https://www.cis.upenn.edu/~aaroth/">Speaker</a></p>

<p>&nbsp;</p>

<p>&nbsp;</p>

<p><strong>Faculty Host:</strong> Anupam Gupta</p>

<p>&nbsp;</p>]]></content:encoded>
         <description><![CDATA[Speaker:�Aaron RothDate:�Friday, Oct 04 on 4:30 PM - 6:00 PMLocation:�Gates Hillman Centers, Rashid Auditorium 4401Detail:Many recent mainstream media articles and popular books have raised alarms over anti-social algorithmic behavior, especially when driven by machine learning. The concerns include leaks of sensitive personal data by predictive models, algorithmic discrimination as a side-effect of machine learning, and inscrutable decisions made by complex models. While standard and legitimate responses to these phenomena include calls for better laws and regulations, researchers in machine learning, statistics and related areas are also working on designing better-behaved algorithms. An explosion of recent research in areas such as differential privacy, algorithmic fairness and algorithmic game theory is forging a new science of socially aware algorithm design. I will survey these developments and attempt to place them in a broader societal context --- and give a taste for what this work is like via a technical anecdote from our own recent research. This talk is based on the forthcoming book The Ethical Algorithm, co-authored with Michael Kearns, and available for pre-order now. � About the Speaker � � Faculty Host: Anupam Gupta �]]></description>
         <author>comet.paws</author>
      </item>
      <item>
         <title><![CDATA[The future of deep learning: DETERMINED AI Info Session]]></title>
         <pubDate>Friday, Oct 04 12:54 PM -0400</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=18131</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;Ameet Talwalkar<br/><b>Date:</b>&nbsp;Friday, Oct 04 on 6:00 PM - 7:00 PM<br/><b>Location:</b>&nbsp;Baker Hall, 253B<br/><b>Detail:<b><p>Join us to discuss the future of deep learning and the underlying AutoML research driving our product vision. Learn more about distributed systems and machine learning opportunities at Determined AI!&nbsp; Co-founder/Chief Scientist and CMU MLD Professor&nbsp;<a href="https://www.cs.cmu.edu/~atalwalk/" target="_blank">Ameet Talwalkar</a>&nbsp;will be joined by Determined AI engineers (and CMU PhDs) <strong>Aaron Harlap</strong> and <strong>Danny Zhu</strong> for an interactive discussion and Q&amp;A.</p>

<p>&nbsp;</p>

<p><a href="https://app.joinhandshake.com/events/352658" target="_blank">RSVP on Handshake</a></p>

<p>&nbsp;</p>

<p>&nbsp;</p>

<p><strong>About Determined AI:&nbsp; </strong>Founded in June 2017,&nbsp;<a href="http://determined.ai/" target="_blank">Determined AI</a>&nbsp;is an early-stage, venture-backed company at the forefront of machine learning technology. Deep learning has enormous promise, but developing practical applications powered by deep learning is extremely complex and expensive. We are making it faster, cheaper, and easier for companies to build intelligent applications. Our software provides workflow and infrastructure automation tools covering the entire model development lifecycle, with a specific focus on deep learning. Our customers are highly skilled ML engineers and domain experts working on exciting problems in biotech, hardware design, adtech, and more.</p>

<p>&nbsp;</p>

<p>&nbsp;</p>

<p>We?re hiring exceptional people to help us solve hard problems, design and build our product, shape our culture, and grow our company. <a href="http://determined.ai/careers" target="_blank">Visit our Careers page</a> to learn more about our available opportunities. Opportunities are available remotely and in San Francisco and Pittsburgh.</p>

<p>&nbsp;</p>

<p>&nbsp;</p>

<p><strong>Our team: </strong>Our founders, Evan Sparks, Neil Conway, and Ameet Talwalkar, met at UC Berkeley&#39;s&nbsp;AmpLab, where they contributed to the Apache Spark, MLlib, and PostgreSQL open source projects. Ameet is also an organizer of the&nbsp;Conference on Systems and Machine Learning&nbsp;(SysML). Our engineering team includes PhDs from Carnegie Mellon University, UC Berkeley, University of Chicago, and University of Texas Austin; they have published extensively at top machine learning and systems conferences including NeurIPS, ICML, SysML, and SOSP.&nbsp;</p>

<p>&nbsp;</p>]]></content:encoded>
         <description><![CDATA[Speaker:�Ameet TalwalkarDate:�Friday, Oct 04 on 6:00 PM - 7:00 PMLocation:�Baker Hall, 253BDetail:Join us to discuss the future of deep learning and the underlying AutoML research driving our product vision. Learn more about distributed systems and machine learning opportunities at Determined AI!� Co-founder/Chief Scientist and CMU MLD Professor�Ameet Talwalkar�will be joined by Determined AI engineers (and CMU PhDs) Aaron Harlap and Danny Zhu for an interactive discussion and Q&A. � RSVP on Handshake � � About Determined AI:� Founded in June 2017,�Determined AI�is an early-stage, venture-backed company at the forefront of machine learning technology. Deep learning has enormous promise, but developing practical applications powered by deep learning is extremely complex and expensive. We are making it faster, cheaper, and easier for companies to build intelligent applications. Our software provides workflow and infrastructure automation tools covering the entire model development lifecycle, with a specific focus on deep learning. Our customers are highly skilled ML engineers and domain experts working on exciting problems in biotech, hardware design, adtech, and more. � � We?re hiring exceptional people to help us solve hard problems, design and build our product, shape our culture, and grow our company. Visit our Careers page to learn more about our available opportunities. Opportunities are available remotely and in San Francisco and Pittsburgh. � � Our team: Our founders, Evan Sparks, Neil Conway, and Ameet Talwalkar, met at UC Berkeley's�AmpLab, where they contributed to the Apache Spark, MLlib, and PostgreSQL open source projects. Ameet is also an organizer of the�Conference on Systems and Machine Learning�(SysML). Our engineering team includes PhDs from Carnegie Mellon University, UC Berkeley, University of Chicago, and University of Texas Austin; they have published extensively at top machine learning and systems conferences including NeurIPS, ICML, SysML, and SOSP.� �]]></description>
         <author>comet.paws</author>
      </item>
      <item>
         <title><![CDATA[Trustworthy Machine Learning from Untrusted Models]]></title>
         <pubDate>Friday, Oct 04 8:44 AM -0400</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=18133</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;TING WANG<br/><b>Date:</b>&nbsp;Monday, Oct 07 on 2:30 PM - 3:30 PM<br/><b>Location:</b>&nbsp;Newell-Simon Hall, 4305<br/><b>Detail:<b><p>Many of today's machine learning (ML) systems are not built from scratch, but are 'composed' from an array of primitive models. This paradigm shift has significantly simplified the system development cycles. Yet, as most primitive models are contributed by untrusted third parties, their lack of regulation and standardization entails profound security implications. In this talk, I will demonstrate that malicious primitive models pose immense threats to the security of ML systems. I will present a general class of backdoor attacks wherein malicious models, once integrated into ML systems, are able to control the behaviors of host systems. I will then describe an offline model inspection tool that effectively vets third-party models for potential backdoors. Finally, I will discuss the potential challenges of realizing the ultimate vision of 'lifelong security' that enforces security assurance throughout the lifecycles of ML systems. Through this talk, I hope to raise the awareness of ML security issues and promote more principled practice of building and operating ML systems.</p> 
<br/>
<br/>    <p>Professor <a href='https://alps-lab.github.io/about/'>Ting Wang</a> is currently an Assistant Professor in the College of Information Sciences and Technology at Penn State. He conducts research at the intersection of machine learning, privacy and security. His ongoing work focuses on making machine learning systems more usable through mitigating security vulnerabilities, enhancing privacy awareness, and increasing decision-making transparency. Prof. Wang is a recipient of the NSF CAREER Award and the IBM Research Innovation Award. He obtained his doctoral degree from Georgia Institute of Technology.</p>]]></content:encoded>
         <description><![CDATA[Speaker:�TING WANGDate:�Monday, Oct 07 on 2:30 PM - 3:30 PMLocation:�Newell-Simon Hall, 4305Detail:Many of today's machine learning (ML) systems are not built from scratch, but are 'composed' from an array of primitive models. This paradigm shift has significantly simplified the system development cycles. Yet, as most primitive models are contributed by untrusted third parties, their lack of regulation and standardization entails profound security implications. In this talk, I will demonstrate that malicious primitive models pose immense threats to the security of ML systems. I will present a general class of backdoor attacks wherein malicious models, once integrated into ML systems, are able to control the behaviors of host systems. I will then describe an offline model inspection tool that effectively vets third-party models for potential backdoors. Finally, I will discuss the potential challenges of realizing the ultimate vision of 'lifelong security' that enforces security assurance throughout the lifecycles of ML systems. Through this talk, I hope to raise the awareness of ML security issues and promote more principled practice of building and operating ML systems. Professor Ting Wang is currently an Assistant Professor in the College of Information Sciences and Technology at Penn State. He conducts research at the intersection of machine learning, privacy and security. His ongoing work focuses on making machine learning systems more usable through mitigating security vulnerabilities, enhancing privacy awareness, and increasing decision-making transparency. Prof. Wang is a recipient of the NSF CAREER Award and the IBM Research Innovation Award. He obtained his doctoral degree from Georgia Institute of Technology.]]></description>
         <author>comet.paws</author>
      </item>
      <item>
         <title><![CDATA[Statistical Methods for Replicability Assessment]]></title>
         <pubDate>Friday, Oct 04 1:50 PM -0400</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=18054</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;Will Fithian <br/><b>Date:</b>&nbsp;Monday, Oct 07 on 4:00 PM - 5:00 PM<br/><b>Location:</b>&nbsp;Scaife Hall 125<br/><b>Detail:<b><p>&nbsp;<strong>Refreshments</strong>: 3:30-4:00, outside Baker Hall 232M</p>

<p><strong>Abstract:</strong> Large-scale replication studies like the Reproducibility Project: Psychology (RP:P) provide invaluable systematic data on scientific replicability, but most analyses and interpretations of the data fail to agree on the definition of &quot;replicability&quot; and disentangle the inexorable consequences of known selection bias from competing explanations. We discuss three concrete definitions of replicability based on (1) whether published findings are mostly correct, (2) how effective replication studies are in reproducing the effect sizes of the original experiments, and (3) whether true effect sizes tend to diminish in replication. We apply techniques from multiple testing and post-selection inference to re-analyze the RP:P data. Among other findings, we estimate that 22 out of 68 (32%) original directional claims were false (upper confidence bound 47%); by comparison, we estimate that among the 33 claims significant at the stricter significance threshold 0.005, only 7% were directionally false (upper confidence bound 18%). Our methods make no distributional assumptions about the true effect sizes.</p>

<p>This is joint work with Kenneth Hung.</p>

<p><strong>Bio:</strong> Will Fithian completed his PhD at Stanford in 2015 advised by Trevor Hastie. He is an assistant professor of statistics at UC Berkeley.&nbsp;His research interests include post-selection inference, adaptive multiple testing, and methodology for ecological statistics.</p>

<p>&nbsp;</p>]]></content:encoded>
         <description><![CDATA[Speaker:�Will Fithian Date:�Monday, Oct 07 on 4:00 PM - 5:00 PMLocation:�Scaife Hall 125Detail:�Refreshments: 3:30-4:00, outside Baker Hall 232M Abstract: Large-scale replication studies like the Reproducibility Project: Psychology (RP:P) provide invaluable systematic data on scientific replicability, but most analyses and interpretations of the data fail to agree on the definition of "replicability" and disentangle the inexorable consequences of known selection bias from competing explanations. We discuss three concrete definitions of replicability based on (1) whether published findings are mostly correct, (2) how effective replication studies are in reproducing the effect sizes of the original experiments, and (3) whether true effect sizes tend to diminish in replication. We apply techniques from multiple testing and post-selection inference to re-analyze the RP:P data. Among other findings, we estimate that 22 out of 68 (32%) original directional claims were false (upper confidence bound 47%); by comparison, we estimate that among the 33 claims significant at the stricter significance threshold 0.005, only 7% were directionally false (upper confidence bound 18%). Our methods make no distributional assumptions about the true effect sizes. This is joint work with Kenneth Hung. Bio: Will Fithian completed his PhD at Stanford in 2015 advised by Trevor Hastie. He is an assistant professor of statistics at UC Berkeley.�His research interests include post-selection inference, adaptive multiple testing, and methodology for ecological statistics. �]]></description>
         <author>comet.paws</author>
      </item>
      <item>
         <title><![CDATA[Recommender Systems: Beyond Machine Learning]]></title>
         <pubDate>Sunday, Oct 06 9:41 PM -0400</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=18075</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;Joseph A. Konstan<br/><b>Date:</b>&nbsp;Tuesday, Oct 08 on 4:00 PM - 5:00 PM<br/><b>Location:</b>&nbsp;Online - Webinar<br/><b>Detail:<b><p>&nbsp;</p>

<p>Recommender systems help users find items of interest and help websites and marketers select items to promote. Today&#39;s recommender systems incorporate sophisticated technology to model user preferences, model item properties, and leverage the experiences of a large community of users in the service of better recommendations. Yet all too often better recommendations&mdash;at least by traditional measures of accuracy and precision&mdash;fail to meet the goal of improving user experience. This talk will take a look at successes and failures in moving beyond basic machine learning approaches to recommender systems to emphasize factors tied to user behavior and experience. Along the way, we will explore approaches to combining human-centered evaluation with data mining and machine learning techniques.</p>

<p>Speakers</p>

<p><img src="https://wcc.on24.com/event/20/87/65/9/rt/1/images/speakerbiowidgetimage1568402609553/joe_konstan.jpg" style="height:140px; width:100px" /></p>

<p><strong>SPEAKER</strong><br />
Joseph A. Konstan<br />
University of Minnesota; ACM Software Systems Award Recipient</p>

<p>Joseph A. Konstan is Distinguished McKnight University Professor and Distinguished University Teaching Professor in the Department of Computer Science and Engineering at the University of Minnesota where he also serves as Associate Dean for Research in the College of Science and Engineering. His research addresses a variety of human-computer interaction issues, including personalization (particularly through recommender systems), eliciting on-line participation, and designing computer systems to improve public health. He is probably best known for his work in collaborative filtering recommenders (the GroupLens project, work which won the ACM Software Systems Award and Seoul Test of Time Award). Dr. Konstan received his Ph.D. from the University of California, Berkeley in 1993. He is a Fellow of the ACM, IEEE, and AAAS, and a member of the CHI Academy. Konstan is co-Chair of the ACM Publications Board, served as President of ACM SIGCHI and is a member of the ACM Council.</p>

<p><img src="https://wcc.on24.com/event/20/87/65/9/rt/1/images/speakerbiowidgetimage1568402767543/bart_knijnenburg.jpeg" style="height:129px; width:100px" /></p>

<p><strong>MODERATOR</strong><br />
Bart Knijnenburg<br />
Clemson University School of Computing</p>

<p>Bart Knijnenburgis an Assistant Professor in Human-Centered Computing at the Clemson University School of Computing where he co-directs the Humans and Technology lab. He holds a B.S. in Innovation Sciences and an M.S. in Human-Technology Interaction from the Eindhoven University of Technology, The Netherlands, an M.A. in Human-Computer Interaction from Carnegie Mellon University, and a PhD in Information and Computer Sciences from UC Irvine. Bart works on privacy decision-making and user-centric evaluation of adaptive systems. His research has received funding from the National Science Foundation, the Department of Defense, and corporate sponsors.</p>]]></content:encoded>
         <description><![CDATA[Speaker:�Joseph A. KonstanDate:�Tuesday, Oct 08 on 4:00 PM - 5:00 PMLocation:�Online - WebinarDetail:� Recommender systems help users find items of interest and help websites and marketers select items to promote. Today's recommender systems incorporate sophisticated technology to model user preferences, model item properties, and leverage the experiences of a large community of users in the service of better recommendations. Yet all too often better recommendations?at least by traditional measures of accuracy and precision?fail to meet the goal of improving user experience. This talk will take a look at successes and failures in moving beyond basic machine learning approaches to recommender systems to emphasize factors tied to user behavior and experience. Along the way, we will explore approaches to combining human-centered evaluation with data mining and machine learning techniques. Speakers SPEAKER Joseph A. Konstan University of Minnesota; ACM Software Systems Award Recipient Joseph A. Konstan is Distinguished McKnight University Professor and Distinguished University Teaching Professor in the Department of Computer Science and Engineering at the University of Minnesota where he also serves as Associate Dean for Research in the College of Science and Engineering. His research addresses a variety of human-computer interaction issues, including personalization (particularly through recommender systems), eliciting on-line participation, and designing computer systems to improve public health. He is probably best known for his work in collaborative filtering recommenders (the GroupLens project, work which won the ACM Software Systems Award and Seoul Test of Time Award). Dr. Konstan received his Ph.D. from the University of California, Berkeley in 1993. He is a Fellow of the ACM, IEEE, and AAAS, and a member of the CHI Academy. Konstan is co-Chair of the ACM Publications Board, served as President of ACM SIGCHI and is a member of the ACM Council. MODERATOR Bart Knijnenburg Clemson University School of Computing Bart Knijnenburgis an Assistant Professor in Human-Centered Computing at the Clemson University School of Computing where he co-directs the Humans and Technology lab. He holds a B.S. in Innovation Sciences and an M.S. in Human-Technology Interaction from the Eindhoven University of Technology, The Netherlands, an M.A. in Human-Computer Interaction from Carnegie Mellon University, and a PhD in Information and Computer Sciences from UC Irvine. Bart works on privacy decision-making and user-centric evaluation of adaptive systems. His research has received funding from the National Science Foundation, the Department of Defense, and corporate sponsors.]]></description>
         <author>chirayu</author>
      </item>
      <item>
         <title><![CDATA[Thesis Proposal: Learning with Graph Structures and Neural Networks]]></title>
         <pubDate>Friday, Oct 04 1:36 PM -0400</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=18138</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;YUEXIN WU<br/><b>Date:</b>&nbsp;Wednesday, Oct 09 on 4:00 PM - 5:00 PM<br/><b>Location:</b>&nbsp;Gates Hillman Centers, Traffic21 Classroom 6501<br/><b>Detail:<b>olecular structures, the prediction of solar-energy farm outputs based on radiation sensor network data, the forecasting of epidemiology outbreaks based on geographical relations among cities and social network interactions and so on. Algorithms for graph-based learning have been developed rapidly, addressing the following fundamental challenges:</p> 
<br/>    <p>? To encode the rich information about each individual node and node combinations in a graph, a.k.a. the graph-based representation learning challenge;<br> ? To recover missing edges when graphs are only partially observed, a.k.a. the graph completion challenge;<br> ? To leverage active learning in graphical settings when labeled nodes are highly sparse, a.k.a. the label sparse challenge;<br> ? To enhance the tractability of training and inference over very large graphs, a.k.a. the scaling challenge.<br> <br> This thesis aims to enhance graph-based machine learning from all the above aspects via the following key contributions:</p> 
<br/>    <p>1. Hierarchical learning of node embedding (H-Emb): Inspired by the great success of BERT and ELMO in recent natural language processing, we propose a new unsupervised learning approach to context-aware node embedding in graphical settings. Different from conventional BERT where the attentions come from the left context or right context of each word, our H-Emb uses all the paths through a specific node to define the rich set of attentions on that node.<br> <br> 2. Graph-enhanced neural learning for node classification: Assuming given graphs are usually incomplete (with missing links) or noisy, directly using them in graph-based classification would be sub-optimal. Thus, we propose to jointly regularize the given graph and optimize the parameters of an NNet during the training of the classifier as our new approach, which combines the strengths of neural classification and spectral transfer of the input graph.<br> <br> 3. Graph convolutional matrix factorization for bipartite edge prediction: For a specific category of graphs, i.e. bipartite graphs, traditional matrix factorization methods could not effectively leverage side information such as similarity measurements within the two groups of nodes. We, therefore, propose to use graph convolutions to enhance the learned factorized representations with the structured side information for better prediction accuracy.<br> <br> 4. Graph-enhanced Active Learning for node classification: Popular AL strategies with successful application in traditional data may not be directly applicable to graphs as they treat all the candidate documents as non-related instances. We propose an approach to active learning over graphs tailored for Graph Neural Networks, which takes both node-internal features and cross-node connections into account for node selection in AL.<br> <br> 5. Successful real-world applications of large-scale graph-based learning: We have investigated the applications of graph-based learning to a variety of real world problems,� including multi-graph based collaborative filtering, graph-based transfer learning across languages, graph-based deep learning for epidemiology prediction, graph-enhanced node classification, edge detection and knowledge base completion; we obtained the state-of-the-art results in each of those domains.</p> 
<br/>    <p><strong>Thesis Committee</strong>:<br> Yiming Yang, (Chair)<br> Aarti Singh (MLD)<br> Leman Akoglu (CSD/Heinz)<br> Huan Liu, (Arizona State University)</p> 
<br/>    <p><a href='https://drive.google.com/file/d/1ukMRRyzkDG4mULoWwA2kuCF5Zig-ik_k/view'>Additional Proposal Information</a><br> �</p>]]></content:encoded>
         <description><![CDATA[Speaker:�YUEXIN WUDate:�Wednesday, Oct 09 on 4:00 PM - 5:00 PMLocation:�Gates Hillman Centers, Traffic21 Classroom 6501Detail:olecular structures, the prediction of solar-energy farm outputs based on radiation sensor network data, the forecasting of epidemiology outbreaks based on geographical relations among cities and social network interactions and so on. Algorithms for graph-based learning have been developed rapidly, addressing the following fundamental challenges: ? To encode the rich information about each individual node and node combinations in a graph, a.k.a. the graph-based representation learning challenge; ? To recover missing edges when graphs are only partially observed, a.k.a. the graph completion challenge; ? To leverage active learning in graphical settings when labeled nodes are highly sparse, a.k.a. the label sparse challenge; ? To enhance the tractability of training and inference over very large graphs, a.k.a. the scaling challenge. This thesis aims to enhance graph-based machine learning from all the above aspects via the following key contributions: 1. Hierarchical learning of node embedding (H-Emb): Inspired by the great success of BERT and ELMO in recent natural language processing, we propose a new unsupervised learning approach to context-aware node embedding in graphical settings. Different from conventional BERT where the attentions come from the left context or right context of each word, our H-Emb uses all the paths through a specific node to define the rich set of attentions on that node. 2. Graph-enhanced neural learning for node classification: Assuming given graphs are usually incomplete (with missing links) or noisy, directly using them in graph-based classification would be sub-optimal. Thus, we propose to jointly regularize the given graph and optimize the parameters of an NNet during the training of the classifier as our new approach, which combines the strengths of neural classification and spectral transfer of the input graph. 3. Graph convolutional matrix factorization for bipartite edge prediction: For a specific category of graphs, i.e. bipartite graphs, traditional matrix factorization methods could not effectively leverage side information such as similarity measurements within the two groups of nodes. We, therefore, propose to use graph convolutions to enhance the learned factorized representations with the structured side information for better prediction accuracy. 4. Graph-enhanced Active Learning for node classification: Popular AL strategies with successful application in traditional data may not be directly applicable to graphs as they treat all the candidate documents as non-related instances. We propose an approach to active learning over graphs tailored for Graph Neural Networks, which takes both node-internal features and cross-node connections into account for node selection in AL. 5. Successful real-world applications of large-scale graph-based learning: We have investigated the applications of graph-based learning to a variety of real world problems,� including multi-graph based collaborative filtering, graph-based transfer learning across languages, graph-based deep learning for epidemiology prediction, graph-enhanced node classification, edge detection and knowledge base completion; we obtained the state-of-the-art results in each of those domains. Thesis Committee: Yiming Yang, (Chair) Aarti Singh (MLD) Leman Akoglu (CSD/Heinz) Huan Liu, (Arizona State University) Additional Proposal Information �]]></description>
         <author>comet.paws</author>
      </item>
      <item>
         <title><![CDATA["Knowledge Embodied in Artifacts": A Problem in Design Epistemology]]></title>
         <pubDate>Sunday, Sep 29 10:53 PM -0400</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=18066</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;Jeffrey Bardzell<br/><b>Date:</b>&nbsp;Friday, Oct 11 on 1:30 PM - 2:30 PM<br/><b>Location:</b>&nbsp;Newell-Simon Hall 1305<br/><b>Detail:<b><p><strong>Abstract:&nbsp; </strong></p>

<p>Among the most exciting developments in HCI research today is the rise of designerly approaches to research: research through design, practice-based research, constructive design, etc. In a 1994 article seeking to establish such an agenda, Christopher Frayling used the provocative phrase, &ldquo;knowledge embodied in artifacts,&rdquo; to capture this research&rsquo;s defining feature. As the HCI community has discovered, however, understanding, accessing, and legitimating &ldquo;knowledge embodied in artifacts&rdquo; has been challenging. It is not always clear how highly particularized objects are supposed to generalize, how they contribute to theory development, or how they might be applied by others.</p>

<p>I argue that practitioners of these approaches have often shoehorned their work into social scientific frameworks of rigor, validity, and generalizability. Instead, design-oriented HCI researchers should pursue a more expansive understanding of &ldquo;HCI research&rdquo; to support &ldquo;knowledge embodied in artifacts&rdquo; as a mode of design research. So, rather than locating intellectual validity and generalizability in propositions, formal arguments, and theoretical paraphrase, we should locate them literally as they are embodied in artifacts themselves. This entails engaging designed artifacts as such, that is, analytically understanding features such as intertextuality (quoting, references, allusions), composition (whole-part coherences), concrete universals (such as design patterns), themes and variations, and polysemy (semantic density, allegory, satire). All of that in turn presupposes new modes of presenting design-oriented HCI research, a process already begun with Pictorials.</p>

<p><strong>Bio:</strong></p>

<p>Jeffrey Bardzell is a Professor of Informatics and Director of the HCI/Design program in the School of Informatics, Computing, and Engineering at Indiana University--Bloomington. His research contributes to design theory and investigations of social innovation, with emphases on critical design, design criticism, creativity and innovation, and intimate experiences. A common thread throughout this work is the use of aesthetics&mdash;including the history of criticism, critical theory, and analytic aesthetics&mdash;to understand how concepts, materials, forms, ideologies, experiential qualities, and creative processes achieve coherence in design objects. He is co-editor of Critical Theory and Interaction Design (MIT Press, 2018) and co-author of Humanistic HCI (Morgan &amp; Claypool, 2015). Bardzell&#39;s work is funded by the National Science Foundation and the Intel Science and Technology Center for Social Computing.&#8203;</p>]]></content:encoded>
         <description><![CDATA[Speaker:�Jeffrey BardzellDate:�Friday, Oct 11 on 1:30 PM - 2:30 PMLocation:�Newell-Simon Hall 1305Detail:Abstract:� Among the most exciting developments in HCI research today is the rise of designerly approaches to research: research through design, practice-based research, constructive design, etc. In a 1994 article seeking to establish such an agenda, Christopher Frayling used the provocative phrase, ?knowledge embodied in artifacts,? to capture this research?s defining feature. As the HCI community has discovered, however, understanding, accessing, and legitimating ?knowledge embodied in artifacts? has been challenging. It is not always clear how highly particularized objects are supposed to generalize, how they contribute to theory development, or how they might be applied by others. I argue that practitioners of these approaches have often shoehorned their work into social scientific frameworks of rigor, validity, and generalizability. Instead, design-oriented HCI researchers should pursue a more expansive understanding of ?HCI research? to support ?knowledge embodied in artifacts? as a mode of design research. So, rather than locating intellectual validity and generalizability in propositions, formal arguments, and theoretical paraphrase, we should locate them literally as they are embodied in artifacts themselves. This entails engaging designed artifacts as such, that is, analytically understanding features such as intertextuality (quoting, references, allusions), composition (whole-part coherences), concrete universals (such as design patterns), themes and variations, and polysemy (semantic density, allegory, satire). All of that in turn presupposes new modes of presenting design-oriented HCI research, a process already begun with Pictorials. Bio: Jeffrey Bardzell is a Professor of Informatics and Director of the HCI/Design program in the School of Informatics, Computing, and Engineering at Indiana University--Bloomington. His research contributes to design theory and investigations of social innovation, with emphases on critical design, design criticism, creativity and innovation, and intimate experiences. A common thread throughout this work is the use of aesthetics?including the history of criticism, critical theory, and analytic aesthetics?to understand how concepts, materials, forms, ideologies, experiential qualities, and creative processes achieve coherence in design objects. He is co-editor of Critical Theory and Interaction Design (MIT Press, 2018) and co-author of Humanistic HCI (Morgan & Claypool, 2015). Bardzell's work is funded by the National Science Foundation and the Intel Science and Technology Center for Social Computing.?]]></description>
         <author>CMU HCII</author>
      </item>
      <item>
         <title><![CDATA[Deep Learning for Robotics]]></title>
         <pubDate>Tuesday, Sep 10 10:21 PM -0400</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=18011</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;PIETER ABBEEL<br/><b>Date:</b>&nbsp;Friday, Oct 11 on 3:00 PM - 4:00 PM<br/><b>Location:</b>&nbsp;Gates Hillman Center 6115<br/><b>Detail:<b><p>Deep Learning for Robotics</p>

<p><strong>Abstract:</strong>&nbsp;Programming robots remains notoriously difficult.&nbsp; Equipping robots with the ability to learn would by-pass the need for what otherwise often ends up being time-consuming task specific programming.&nbsp; This talk will describe recent progress in deep reinforcement learning (robots learning through their own trial and error), in apprenticeship learning (robots learning from observing people), and in meta-learning for action (robots learning to learn). &nbsp; This work has led to new robotic capabilities in manipulation, locomotion, and flight, with the same approach underlying advances in each of these domains.</p>

<p><strong>Brief Bio:</strong>&nbsp;Professor Pieter Abbeel is Director of the Berkeley Robot Learning Lab and Co-Director of the Berkeley Artificial Intelligence (BAIR) Lab. Abbeel&rsquo;s research strives to build ever more intelligent systems, which has his lab push the frontiers of deep reinforcement learning, deep imitation learning, deep unsupervised learning, transfer learning, meta-learning, and learning to learn, as well as study the influence of AI on society.&nbsp; His lab also investigates how AI could advance other science and engineering disciplines.&nbsp; Abbeel&rsquo;s Intro to AI class has been taken by over 100K students through edX, and his Deep RL and Deep Unsupervised Learning materials are standard references for AI researchers.&nbsp; Abbeel has founded three companies: Gradescope (AI to help teachers with grading homework and exams), Covariant (AI for robotic automation of warehouses and factories), and Berkeley Open Arms (low-cost, highly capable 7-dof robot arms), advises many AI and robotics start-ups, and is a frequently sought after speaker worldwide for C-suite sessions on AI future and strategy.&nbsp; Abbeel has received many awards and honors, including the PECASE, NSF-CAREER, ONR-YIP, Darpa-YFA, TR35.&nbsp; His work is frequently featured in the press, including the New York Times, Wall Street Journal, BBC, Rolling Stone, Wired, and Tech Review.</p>

<p><strong>Host:</strong>&nbsp;David Held</p>

<p><strong>For Appointments:</strong>&nbsp;Stephanie Matvey (smatvey@andrew.cmu.edu)</p>]]></content:encoded>
         <description><![CDATA[Speaker:�PIETER ABBEELDate:�Friday, Oct 11 on 3:00 PM - 4:00 PMLocation:�Gates Hillman Center 6115Detail:Deep Learning for Robotics Abstract:�Programming robots remains notoriously difficult.� Equipping robots with the ability to learn would by-pass the need for what otherwise often ends up being time-consuming task specific programming.� This talk will describe recent progress in deep reinforcement learning (robots learning through their own trial and error), in apprenticeship learning (robots learning from observing people), and in meta-learning for action (robots learning to learn). � This work has led to new robotic capabilities in manipulation, locomotion, and flight, with the same approach underlying advances in each of these domains. Brief Bio:�Professor Pieter Abbeel is Director of the Berkeley Robot Learning Lab and Co-Director of the Berkeley Artificial Intelligence (BAIR) Lab. Abbeel?s research strives to build ever more intelligent systems, which has his lab push the frontiers of deep reinforcement learning, deep imitation learning, deep unsupervised learning, transfer learning, meta-learning, and learning to learn, as well as study the influence of AI on society.� His lab also investigates how AI could advance other science and engineering disciplines.� Abbeel?s Intro to AI class has been taken by over 100K students through edX, and his Deep RL and Deep Unsupervised Learning materials are standard references for AI researchers.� Abbeel has founded three companies: Gradescope (AI to help teachers with grading homework and exams), Covariant (AI for robotic automation of warehouses and factories), and Berkeley Open Arms (low-cost, highly capable 7-dof robot arms), advises many AI and robotics start-ups, and is a frequently sought after speaker worldwide for C-suite sessions on AI future and strategy.� Abbeel has received many awards and honors, including the PECASE, NSF-CAREER, ONR-YIP, Darpa-YFA, TR35.� His work is frequently featured in the press, including the New York Times, Wall Street Journal, BBC, Rolling Stone, Wired, and Tech Review. Host:�David Held For Appointments:�Stephanie Matvey (smatvey@andrew.cmu.edu)]]></description>
         <author>OliverHao</author>
      </item>
      <item>
         <title><![CDATA[Dissertation Defense: Algorithms, Applications and Systems Towards Interpretable Pattern Mining from Multi-Aspect Data]]></title>
         <pubDate>Monday, Oct 07 6:00 PM -0400</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=18147</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;Xidao Wen<br/><b>Date:</b>&nbsp;Monday, Oct 14 on 9:00 AM - 12:00 PM<br/><b>Location:</b>&nbsp;Room 828, Information Sciences Building, 135 N Bellefield Ave, Pittsburgh, PA 15213<br/><b>Detail:<b><p>&nbsp;</p>

<p><strong>Committee:</strong></p>

<ul>
	<li>Dr. Yu-Ru Lin, Associate Professor, School of Computing and Information, University of Pittsburgh</li>
	<li>Dr. Konstantinos Pelechrinis, Associate Professor, School of Computing and Information, University of Pittsburgh</li>
	<li>Dr. Peter Brusilovsky, Professor, School of Computing and Information, University of Pittsburgh</li>
	<li>Dr. Christos Faloutsos, Professor, School of Computer Science, Carnegie Mellon University</li>
</ul>

<p><strong>Abstract:</strong></p>

<p>How do humans move around in the urban space and how do they differ when the city undergoes terrorist attacks? How do users behave in Massive Open Online courses~(MOOCs) and how do they differ if some of them achieve certificates while some of them not? What areas in the court elite players, such as Stephen Curry, LeBron James, like to make their shots in the course of the game? How can we uncover the hidden habits that govern our online purchases? Are there unspoken agendas in how different states pass legislation of certain kinds?&nbsp; At the heart of these seemingly unconnected puzzles is this same mystery of multi-aspect mining, i.g., how can we <em>mine</em>&nbsp;and <em>interpret</em>&nbsp;the hidden pattern from a dataset that simultaneously reveals the associations, or changes of the associations, among various <em>aspects</em>&nbsp;of the data (e.g., a shot could be described with three aspects, player, time of the game, and area in the court)? Solving this problem could open gates to a deep understanding of underlying mechanisms for many real-world phenomena. While much of the research in <em>multi-aspect</em>&nbsp;mining contribute broad scope of innovations in the mining part, interpretation of patterns from the perspective of users (or domain experts) is often overlooked. Questions like what do they require for patterns, how good are the patterns, or how to read them, have barely been addressed. Without efficient and effective ways of involving users in the process of multi-aspect mining, the results are likely to lead to something difficult for them to comprehend.&nbsp;</p>

<p>This dissertation proposes the M<small>^3</small> framework, which consists of <strong>m</strong>ultiplex pattern discovery, <strong>m</strong>ultifaceted pattern evaluation, and <strong>m</strong>ultipurpose pattern presentation, to tackle the challenges of multi-aspect pattern discovery. Based on this framework, we develop algorithms, applications, and analytic systems to enable interpretable pattern discovery from multi-aspect data. Following the concept of meaningful multiplex pattern discovery, we propose <em>PairFac</em> to close the gap between human information needs and naive mining optimization. We demonstrate its effectiveness in the context of impact discovery in the aftermath of urban disasters. We develop <em>iDisc</em> to target the crossing of multiplex pattern discovery with multifaceted pattern evaluation. <em>iDisc&nbsp;</em>meets the specific information need in understanding multi-level, contrastive behavior patterns. As an example, we use <em>iDisc&nbsp;</em>to predict student performance outcomes in Massive Open Online Courses given users&#39; latent behaviors. <em>FacIt</em> is an interactive visual analytic system that sits at the intersection of all three components and enables for interpretable, fine-tunable, and scrutinizable pattern discovery from multi-aspect data. We demonstrate each work&#39;s significance and implications in its respective problem context. As a whole, this series of studies is an effort to instantiate the M<small>^3</small> framework and push the field of multi-aspect mining towards a more human-centric process in real-world applications.</p>]]></content:encoded>
         <description><![CDATA[Speaker:�Xidao WenDate:�Monday, Oct 14 on 9:00 AM - 12:00 PMLocation:�Room 828, Information Sciences Building, 135 N Bellefield Ave, Pittsburgh, PA 15213Detail:� Committee: Dr. Yu-Ru Lin, Associate Professor, School of Computing and Information, University of Pittsburgh Dr. Konstantinos Pelechrinis, Associate Professor, School of Computing and Information, University of Pittsburgh Dr. Peter Brusilovsky, Professor, School of Computing and Information, University of Pittsburgh Dr. Christos Faloutsos, Professor, School of Computer Science, Carnegie Mellon University Abstract: How do humans move around in the urban space and how do they differ when the city undergoes terrorist attacks? How do users behave in Massive Open Online courses~(MOOCs) and how do they differ if some of them achieve certificates while some of them not? What areas in the court elite players, such as Stephen Curry, LeBron James, like to make their shots in the course of the game? How can we uncover the hidden habits that govern our online purchases? Are there unspoken agendas in how different states pass legislation of certain kinds?� At the heart of these seemingly unconnected puzzles is this same mystery of multi-aspect mining, i.g., how can we mine�and interpret�the hidden pattern from a dataset that simultaneously reveals the associations, or changes of the associations, among various aspects�of the data (e.g., a shot could be described with three aspects, player, time of the game, and area in the court)? Solving this problem could open gates to a deep understanding of underlying mechanisms for many real-world phenomena. While much of the research in multi-aspect�mining contribute broad scope of innovations in the mining part, interpretation of patterns from the perspective of users (or domain experts) is often overlooked. Questions like what do they require for patterns, how good are the patterns, or how to read them, have barely been addressed. Without efficient and effective ways of involving users in the process of multi-aspect mining, the results are likely to lead to something difficult for them to comprehend.� This dissertation proposes the M^3 framework, which consists of multiplex pattern discovery, multifaceted pattern evaluation, and multipurpose pattern presentation, to tackle the challenges of multi-aspect pattern discovery. Based on this framework, we develop algorithms, applications, and analytic systems to enable interpretable pattern discovery from multi-aspect data. Following the concept of meaningful multiplex pattern discovery, we propose PairFac to close the gap between human information needs and naive mining optimization. We demonstrate its effectiveness in the context of impact discovery in the aftermath of urban disasters. We develop iDisc to target the crossing of multiplex pattern discovery with multifaceted pattern evaluation. iDisc�meets the specific information need in understanding multi-level, contrastive behavior patterns. As an example, we use iDisc�to predict student performance outcomes in Massive Open Online Courses given users' latent behaviors. FacIt is an interactive visual analytic system that sits at the intersection of all three components and enables for interpretable, fine-tunable, and scrutinizable pattern discovery from multi-aspect data. We demonstrate each work's significance and implications in its respective problem context. As a whole, this series of studies is an effort to instantiate the M^3 framework and push the field of multi-aspect mining towards a more human-centric process in real-world applications.]]></description>
         <author>bjw71</author>
      </item>
      <item>
         <title><![CDATA[Elo, I Love You Won't You Tell Me Your K]]></title>
         <pubDate>Monday, Sep 30 2:29 PM -0400</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=18118</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;Michael Yudelson<br/><b>Date:</b>&nbsp;Wednesday, Oct 16 on 9:00 AM - 10:00 AM<br/><b>Location:</b>&nbsp;IS 828, Information Science Building, 135 N. Bellefield Ave.<br/><b>Detail:<b><p>Elo is a rating schema used for tracking player level in individual and, sometimes, team sports, most notably &ndash; in chess. Also, it has found use in the area of tracking learner proficiency. Similar to the 1PL IRT (Rasch), Elo rating schema could be extended to serve the most demanding needs of learner skill tracking. Elo&rsquo;s advantage is that it has fewer parameters. However, the computational efficiency side of the search for the best-fitting values of these parameters is rarely discussed. In this paper, we are focusing on questions of implementing Elo and a gradient-based approach to find optimal values of its parameters. Also, we compare several variants of Elo to learning modeling approaches like Bayesian Knowledge Tracing. Our results show that the use of analytical gradients results in computational and, sometimes, statistical fit improvements on small and large datasets alike.</p>]]></content:encoded>
         <description><![CDATA[Speaker:�Michael YudelsonDate:�Wednesday, Oct 16 on 9:00 AM - 10:00 AMLocation:�IS 828, Information Science Building, 135 N. Bellefield Ave.Detail:Elo is a rating schema used for tracking player level in individual and, sometimes, team sports, most notably ? in chess. Also, it has found use in the area of tracking learner proficiency. Similar to the 1PL IRT (Rasch), Elo rating schema could be extended to serve the most demanding needs of learner skill tracking. Elo?s advantage is that it has fewer parameters. However, the computational efficiency side of the search for the best-fitting values of these parameters is rarely discussed. In this paper, we are focusing on questions of implementing Elo and a gradient-based approach to find optimal values of its parameters. Also, we compare several variants of Elo to learning modeling approaches like Bayesian Knowledge Tracing. Our results show that the use of analytical gradients results in computational and, sometimes, statistical fit improvements on small and large datasets alike.]]></description>
         <author>peterb</author>
      </item>
      <item>
         <title><![CDATA[Designing Learning Analytics for Humans with Humans]]></title>
         <pubDate>Wednesday, Oct 16 4:07 PM -0400</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=18001</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;Alyssa Wise<br/><b>Date:</b>&nbsp;Wednesday, Oct 16 on 12:00 PM - 1:00 PM<br/><b>Location:</b>&nbsp;Webinar<br/><b>Detail:<b><h3><strong style="font-size:13px">Abstract:</strong></h3>

<p>Learning analytics (LA) is a technology for enabling better decision-making by teachers, students, and other educational stakeholders by providing them with timely and actionable information about learning-in-process on an ongoing basis. To be effective LA tools must thus not only be technically robust but also designed to support use by real people. One powerful strategy for achieving this goal is to involve those who will (hopefully!) use the learning analytics in their design. This can be done by observing existing (pre-analytic) teaching and learning practices, gathering information from intended users, or directly engaging them in participatory design. Such attention to people and context contributes to the development of Human-Centered Learning Analytics (see the recent&nbsp;<a href="https://learning-analytics.info/journals/index.php/JLA/issue/view/463" target="_blank">special section in JLA 6(2)</a>).</p>

<p>In this webinar, I&#39;ll present a diverse set of examples of the ways that NYU&#39;s&nbsp;<a href="https://www.nyu.edu/learn-analytics" target="_blank">Learning Analytics Research Network</a>&nbsp;(NYU-LEARN) is including educators and students in the process of building and implementing learning analytics. We&#39;ll look at examples of how to: involve students in the creation and revision of learning analytics solutions for their own use; work with instructors to align analytically available metrics with valued course pedagogy; and partner with an educational team to design and implement interventions based on at-risk students predictions. Webinar attendees will gain a sense of both the conceptual issues and practical concerns involved in designing learning analytics for humans with humans.</p>

<p><img alt="Professor Alyssa Wise Photo" src="https://cdn.evbuc.com/eventlogos/243349693/alyssa-1.jpg" style="margin-left:auto; margin-right:auto" /></p>

<p><strong>Biography:</strong><br />
Dr. Alyssa Wise is Associate Professor of Learning Sciences and Educational Technology at New York University and the Director of LEARN, NYU&#39;s pioneering university-wide&nbsp;<a href="https://www.nyu.edu/learn-analytics" target="_blank">Learning Analytics Research Network</a>. She holds a Ph.D. in Learning Sciences and an M.S. in Instructional Systems Technology from Indiana University and a B.S. in Chemistry from Yale University. Dr. Wise&rsquo;s research is situated at the intersection of learning and educational data sciences, focusing on the design of learning analytics systems that are theoretically grounded, computationally robust, and pedagogically useful for informing teaching and learning. Dr. Wise serves as Co-Editor-in-Chief of the Journal of Learning Analytics is a Co-Editor of the Handbook of Learning Analytics.</p>

<p>&nbsp;</p>]]></content:encoded>
         <description><![CDATA[Speaker:�Alyssa WiseDate:�Wednesday, Oct 16 on 12:00 PM - 1:00 PMLocation:�WebinarDetail:Abstract: Learning analytics (LA) is a technology for enabling better decision-making by teachers, students, and other educational stakeholders by providing them with timely and actionable information about learning-in-process on an ongoing basis. To be effective LA tools must thus not only be technically robust but also designed to support use by real people. One powerful strategy for achieving this goal is to involve those who will (hopefully!) use the learning analytics in their design. This can be done by observing existing (pre-analytic) teaching and learning practices, gathering information from intended users, or directly engaging them in participatory design. Such attention to people and context contributes to the development of Human-Centered Learning Analytics (see the recent�special section in JLA 6(2)). In this webinar, I'll present a diverse set of examples of the ways that NYU's�Learning Analytics Research Network�(NYU-LEARN) is including educators and students in the process of building and implementing learning analytics. We'll look at examples of how to: involve students in the creation and revision of learning analytics solutions for their own use; work with instructors to align analytically available metrics with valued course pedagogy; and partner with an educational team to design and implement interventions based on at-risk students predictions. Webinar attendees will gain a sense of both the conceptual issues and practical concerns involved in designing learning analytics for humans with humans. Biography: Dr. Alyssa Wise is Associate Professor of Learning Sciences and Educational Technology at New York University and the Director of LEARN, NYU's pioneering university-wide�Learning Analytics Research Network. She holds a Ph.D. in Learning Sciences and an M.S. in Instructional Systems Technology from Indiana University and a B.S. in Chemistry from Yale University. Dr. Wise?s research is situated at the intersection of learning and educational data sciences, focusing on the design of learning analytics systems that are theoretically grounded, computationally robust, and pedagogically useful for informing teaching and learning. Dr. Wise serves as Co-Editor-in-Chief of the Journal of Learning Analytics is a Co-Editor of the Handbook of Learning Analytics. �]]></description>
         <author>comet.paws</author>
      </item>
      <item>
         <title><![CDATA[Challenges for the Future of Artificial Intelligence in Education]]></title>
         <pubDate>Friday, Nov 08 11:45 AM -0500</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=18406</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;Ryan Baker<br/><b>Date:</b>&nbsp;Wednesday, Oct 16 on 1:00 PM - 2:00 PM<br/><b>Location:</b>&nbsp;Webinar<br/><b>Detail:<b><p><a href="https://www.alelo.com/2018/05/alelo-webinar-series-on-the-future-of-ai-in-education/#RyanBaker">Ryan Baker</a><br />
Associate Professor, University of Pennsylvania and Director of the Penn Center for Learning Analytics</p>

<p>As the talks in this seminar series have shown, artificial intelligence has had a positive impact on education. After only a brief number of years of research, we have accurate models of constructs many didn&rsquo;t think we could model, dashboards and interventions and (some) evidence they work, and scaled solutions that are being used to change student outcomes. As a field, we have solved some challenging problems. So, what&rsquo;s next? In this talk, I&rsquo;ll discuss a few hard problems that could block AI in education from reaching its full potential; some of the big goals I think we can strive to achieve; some of the grand challenges we will need to &mdash; and I think can &mdash; solve; and perhaps most importantly &mdash; how we&rsquo;ll know if we&rsquo;ve gotten there.</p>

<p>&nbsp;</p>]]></content:encoded>
         <description><![CDATA[Speaker:�Ryan BakerDate:�Wednesday, Oct 16 on 1:00 PM - 2:00 PMLocation:�WebinarDetail:Ryan Baker Associate Professor, University of Pennsylvania and Director of the Penn Center for Learning Analytics As the talks in this seminar series have shown, artificial intelligence has had a positive impact on education. After only a brief number of years of research, we have accurate models of constructs many didn?t think we could model, dashboards and interventions and (some) evidence they work, and scaled solutions that are being used to change student outcomes. As a field, we have solved some challenging problems. So, what?s next? In this talk, I?ll discuss a few hard problems that could block AI in education from reaching its full potential; some of the big goals I think we can strive to achieve; some of the grand challenges we will need to ? and I think can ? solve; and perhaps most importantly ? how we?ll know if we?ve gotten there. �]]></description>
         <author>comet.paws</author>
      </item>
      <item>
         <title><![CDATA[Update on Modern Data Analytics Tools]]></title>
         <pubDate>Tuesday, Oct 08 3:52 PM -0400</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=18155</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;Deepak Majeti<br/><b>Date:</b>&nbsp;Wednesday, Oct 16 on 3:00 PM - 4:00 PM<br/><b>Location:</b>&nbsp;5317 Sennott Square<br/><b>Detail:<b><p>Ever wondered how organizations are handling the vast amounts of data being generated today? Data Analytics traditionally ran on a single monolithic database but have now evolved to depend on several specialized components including at the compute, storage, and file-format layers. In this talk, we will discuss some of these newer tools and how they integrate to provide data analytics at scale.</p>

<p>Separating storage and compute enabled complex data pipelines and simplified scaling. However, the challenges posed by this separation include consistent results, locality, data security, and ease of use. I will describe some tools that are being developed for the aforementioned challenges.</p>

<p>Another interesting facet of this space is the co-existence of open-source and enterprise products and I will share some insights into how they work together.</p>]]></content:encoded>
         <description><![CDATA[Speaker:�Deepak MajetiDate:�Wednesday, Oct 16 on 3:00 PM - 4:00 PMLocation:�5317 Sennott SquareDetail:Ever wondered how organizations are handling the vast amounts of data being generated today? Data Analytics traditionally ran on a single monolithic database but have now evolved to depend on several specialized components including at the compute, storage, and file-format layers. In this talk, we will discuss some of these newer tools and how they integrate to provide data analytics at scale. Separating storage and compute enabled complex data pipelines and simplified scaling. However, the challenges posed by this separation include consistent results, locality, data security, and ease of use. I will describe some tools that are being developed for the aforementioned challenges. Another interesting facet of this space is the co-existence of open-source and enterprise products and I will share some insights into how they work together.]]></description>
         <author>ISP Admin</author>
      </item>
      <item>
         <title><![CDATA[HOFMANN LECTURE: Health Monitoring with Machine Learning and Wireless Sensors]]></title>
         <pubDate>Friday, Sep 27 11:22 AM -0400</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=18049</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;Dina Katabi<br/><b>Date:</b>&nbsp;Thursday, Oct 17 on 4:00 PM - 5:00 PM<br/><b>Location:</b>&nbsp;Alumni Hall, Auditorium, 7th Floor<br/><b>Detail:<b><p><strong>Dina Katabi, PhD,</strong>&nbsp;has said that the integration of medicine and computer science will drive many of the innovations and future developments in health and health care. At the forefront of this intersection, Katabi studies mobile and wireless technology&rsquo;s application to medicine. Her research focuses on innovations in mobile computing, wireless sensing, and machine learning with application to digital health.</p>

<p>Katabi and her lab members have demonstrated the use of Wi-Fi-frequency radio waves for imaging and detection of motion through solid objects. They have also shown how ultralow-power radio signals can measure human respiration and heart rates from dozens of yards away. Several start-up companies, including PiCharging and Emerald, have been spun out of Katabi&rsquo;s lab.</p>

<p>Katabi continues to study and refine the applications and use of artificial intelligence and machine learning models that analyze radio signals to extract physiological information and noninvasively monitor health. More broadly, her research has spanned the development of technologies and algorithms that have improved Wi-Fi and cellular performance and the use of mobile systems and wireless networks. At MIT, she is director of the Center for Wireless Networks and Mobile Computing and leader of the NETMIT research group at the Computer Science and Artificial Intelligence Laboratory.</p>

<p>Katabi received her bachelor&rsquo;s degree from Damascus University in her native Syria and her MS and PhD in computer science from MIT. She received the Association for Computing Machinery&rsquo;s Grace Murray Hopper Award and the Institute of Electrical and Electronics Engineers&rsquo; William R. Bennett Prize. She was named a MacArthur Foundation fellow in 2013 and was elected to the National Academy of Engineering in 2017.&nbsp;</p>

<p>&nbsp;</p>]]></content:encoded>
         <description><![CDATA[Speaker:�Dina KatabiDate:�Thursday, Oct 17 on 4:00 PM - 5:00 PMLocation:�Alumni Hall, Auditorium, 7th FloorDetail:Dina Katabi, PhD,�has said that the integration of medicine and computer science will drive many of the innovations and future developments in health and health care. At the forefront of this intersection, Katabi studies mobile and wireless technology?s application to medicine. Her research focuses on innovations in mobile computing, wireless sensing, and machine learning with application to digital health. Katabi and her lab members have demonstrated the use of Wi-Fi-frequency radio waves for imaging and detection of motion through solid objects. They have also shown how ultralow-power radio signals can measure human respiration and heart rates from dozens of yards away. Several start-up companies, including PiCharging and Emerald, have been spun out of Katabi?s lab. Katabi continues to study and refine the applications and use of artificial intelligence and machine learning models that analyze radio signals to extract physiological information and noninvasively monitor health. More broadly, her research has spanned the development of technologies and algorithms that have improved Wi-Fi and cellular performance and the use of mobile systems and wireless networks. At MIT, she is director of the Center for Wireless Networks and Mobile Computing and leader of the NETMIT research group at the Computer Science and Artificial Intelligence Laboratory. Katabi received her bachelor?s degree from Damascus University in her native Syria and her MS and PhD in computer science from MIT. She received the Association for Computing Machinery?s Grace Murray Hopper Award and the Institute of Electrical and Electronics Engineers? William R. Bennett Prize. She was named a MacArthur Foundation fellow in 2013 and was elected to the National Academy of Engineering in 2017.� �]]></description>
         <author>PatHealy</author>
      </item>
      <item>
         <title><![CDATA[What Revolution? Public Health and the Push to Personalize]]></title>
         <pubDate>Monday, Sep 30 10:10 PM -0400</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=18105</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;Timothy Caulfield<br/><b>Date:</b>&nbsp;Friday, Oct 18 on 11:00 AM - 12:00 PM<br/><b>Location:</b>&nbsp;Magee-Womens Hospital of UPMC Zero Level - Auditorium<br/><b>Detail:<b><p>The idea that we are in the midst of a genetic revolution has been with us for decades. The latest iteration of this promise of paradigm-shifting transformation comes in the guise of &quot;personalized medicine&quot; - which, we are consistently told, will revolutionize our healthcare system and reduce the burden of chronic disease. But can personalized medicine live up to the hype? In this presentation Caulfield critiques the promises associated with this biomedical &quot;revolution&quot; and the broader social trend to personalize everything from our diets to our exercise to the wine we drink.</p>

<p>&nbsp;</p>

<p><strong>About Timothy Caulfield, LLM, FRSC, FCAHS</strong>&nbsp; &nbsp; &nbsp;&nbsp;</p>

<p>Timothy Caulfield is a Canada Research Chair in Health Law and Policy, a Professor in the Faculty of Law and the School of Public Health, and Research Director of the Health Law Institute at the University of Alberta. His interdisciplinary research on topics like stem cells, genetics, research ethics, the public representations of science and health policy issues has allowed him to publish over 350 academic articles. He has won numerous academic and writing awards and is a Fellow of the Royal Society of Canada and the Canadian Academy of Health Sciences. He contributes frequently to the popular press and is the author of two national bestsellers: <em>The Cure for Everything: Untangling the Twisted Messages about Health, Fitness and Happiness</em> (Penguin 2012) and <em>Is Gwyneth Paltrow Wrong About Everything?: When Celebrity Culture and Science Clash</em> (Penguin 2015). His most recent book is The Vaccination Picture (Penguin, 2017). Caulfield is also the host and co-producer of the award winning documentary TV show, <em>A User&#39;s Guide to Cheating Death</em>, which has been shown in over 60 countries and is currently streaming on Netflix.</p>

<p>&nbsp;</p>

<p>No pre-registration is required and all are welcome to attend. For more information or to submit advance questions, email <a href="mailto:askirb@pitt.edu" target="_blank">askirb@pitt.edu.</a></p>]]></content:encoded>
         <description><![CDATA[Speaker:�Timothy CaulfieldDate:�Friday, Oct 18 on 11:00 AM - 12:00 PMLocation:�Magee-Womens Hospital of UPMC Zero Level - AuditoriumDetail:The idea that we are in the midst of a genetic revolution has been with us for decades. The latest iteration of this promise of paradigm-shifting transformation comes in the guise of "personalized medicine" - which, we are consistently told, will revolutionize our healthcare system and reduce the burden of chronic disease. But can personalized medicine live up to the hype? In this presentation Caulfield critiques the promises associated with this biomedical "revolution" and the broader social trend to personalize everything from our diets to our exercise to the wine we drink. � About Timothy Caulfield, LLM, FRSC, FCAHS� � �� Timothy Caulfield is a Canada Research Chair in Health Law and Policy, a Professor in the Faculty of Law and the School of Public Health, and Research Director of the Health Law Institute at the University of Alberta. His interdisciplinary research on topics like stem cells, genetics, research ethics, the public representations of science and health policy issues has allowed him to publish over 350 academic articles. He has won numerous academic and writing awards and is a Fellow of the Royal Society of Canada and the Canadian Academy of Health Sciences. He contributes frequently to the popular press and is the author of two national bestsellers: The Cure for Everything: Untangling the Twisted Messages about Health, Fitness and Happiness (Penguin 2012) and Is Gwyneth Paltrow Wrong About Everything?: When Celebrity Culture and Science Clash (Penguin 2015). His most recent book is The Vaccination Picture (Penguin, 2017). Caulfield is also the host and co-producer of the award winning documentary TV show, A User's Guide to Cheating Death, which has been shown in over 60 countries and is currently streaming on Netflix. � No pre-registration is required and all are welcome to attend. For more information or to submit advance questions, email askirb@pitt.edu.]]></description>
         <author>comet.paws</author>
      </item>
      <item>
         <title><![CDATA[Research on the Edge of the Expanding Sphere V. 2.0]]></title>
         <pubDate>Friday, Sep 27 11:26 AM -0400</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=18076</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;Alfred Spector<br/><b>Date:</b>&nbsp;Friday, Oct 18 on 4:00 PM - 5:00 PM<br/><b>Location:</b>&nbsp;Alumni Hall, Auditorium, 7th Floor<br/><b>Detail:<b><p>&nbsp;</p>

<p>Throughout his career,&nbsp;<strong>Alfred Spector, PhD,</strong>&nbsp;has sought to address research challenges in computer science and promote the importance of computer science across disciplines. As chief technology officer and head of engineering at Two Sigma Investments, Spector and colleagues harness big data and technological methods like artificial intelligence, machine learning, and distributed computing to advance investment and trading strategies. Broadly, the company seeks to use the scientific method to find connections in the world&rsquo;s data to improve investing and to fund research, education, and charitable foundations.</p>

<p>Previously, Spector was vice president of research and special initiatives at Google, where he oversaw a variety of research programs and helped Google connect with the university research community. Spector also helped lead Google.org&rsquo;s efforts to create products and advocate for policies addressing global challenges like education, inclusion, and crisis response.</p>

<p>Prior to these roles, Spector was vice president of strategy and technology at IBM Software Group and vice president of services and software research across IBM. He was also an associate professor of computer science at Carnegie Mellon University, where he specialized in distributed computing, which connects multiple components on multiple computers to operate as a single system. Spector founded and was CEO of Transarc Corporation, a pioneer in distributed transaction processing and wide area file systems, which are key computing features.</p>

<p>Spector earned his bachelor&rsquo;s degree in applied mathematics at Harvard University before earning his computer science PhD at Stanford University. He has been elected to the American Academy of Arts and Sciences and to the National Academy of Engineering. He is a fellow of the Association for Computing Machinery and a recipient of its Software System Award, as well as a fellow of the Institute of Electrical and Electronics Engineers.</p>

<p>&nbsp;</p>]]></content:encoded>
         <description><![CDATA[Speaker:�Alfred SpectorDate:�Friday, Oct 18 on 4:00 PM - 5:00 PMLocation:�Alumni Hall, Auditorium, 7th FloorDetail:� Throughout his career,�Alfred Spector, PhD,�has sought to address research challenges in computer science and promote the importance of computer science across disciplines. As chief technology officer and head of engineering at Two Sigma Investments, Spector and colleagues harness big data and technological methods like artificial intelligence, machine learning, and distributed computing to advance investment and trading strategies. Broadly, the company seeks to use the scientific method to find connections in the world?s data to improve investing and to fund research, education, and charitable foundations. Previously, Spector was vice president of research and special initiatives at Google, where he oversaw a variety of research programs and helped Google connect with the university research community. Spector also helped lead Google.org?s efforts to create products and advocate for policies addressing global challenges like education, inclusion, and crisis response. Prior to these roles, Spector was vice president of strategy and technology at IBM Software Group and vice president of services and software research across IBM. He was also an associate professor of computer science at Carnegie Mellon University, where he specialized in distributed computing, which connects multiple components on multiple computers to operate as a single system. Spector founded and was CEO of Transarc Corporation, a pioneer in distributed transaction processing and wide area file systems, which are key computing features. Spector earned his bachelor?s degree in applied mathematics at Harvard University before earning his computer science PhD at Stanford University. He has been elected to the American Academy of Arts and Sciences and to the National Academy of Engineering. He is a fellow of the Association for Computing Machinery and a recipient of its Software System Award, as well as a fellow of the Institute of Electrical and Electronics Engineers. �]]></description>
         <author>PatHealy</author>
      </item>
      <item>
         <title><![CDATA[Special Priorities in Deep Learning and AI]]></title>
         <pubDate>Friday, Oct 18 1:01 AM -0400</pubDate>
         <link>http://halley.exp.sis.pitt.edu/comet/presentColloquium.do?col_id=18200</link>
         <content:encoded><![CDATA[<b>Speaker:</b>&nbsp;Kenji Kawaguchi<br/><b>Date:</b>&nbsp;Tuesday, Oct 22 on 12:00 PM - 1:00 PM<br/><b>Location:</b>&nbsp;Newell-Simon Hall 3305, CMU<br/><b>Detail:<b><p><br />
<strong>Abstract:</strong>&nbsp;Deep learning and AI have provided high-impact data-driven methods in various applications. However, theoretical guarantees on deep learning and AI tend to provide too pessimistic insights with a gap from practical observations, because of hidden special properties of deep learning and AI problems. Identifying such special properties can provide novel theoretical insights, and is potentially helpful for designing methods and deriving better guarantees. In this talk, I will discuss special properties on non-convex optimization landscapes of deep neural networks and machine learning models, as well as their implications on gradient descent methods and the results on real-world applications based on theoretical insights.&nbsp;&nbsp;</p>

<p>&nbsp;</p>

<p><strong>Bio:</strong>&nbsp;Kenji Kawaguchi is a Ph.D. candidate at Massachusetts Institute of Technology (MIT), advised by Prof. Leslie Pack Kaelbling. He received his M.S. in Electrical Engineering and Computer Science from MIT. His research interests span machine learning, deep learning, artificial intelligence, convex/nonconvex optimization and Bayesian optimization. His research has been cited widely in academia and used in classes. He was invited to speak at the 2019 International Congress on Industrial and Applied Mathematics Minisymposium on Theoretical Foundations of Deep Learning. In 2018, he was invited for a summer research visit at Microsoft Research in Redmond. He was awarded the Funai Overseas Scholarship in 2014 and was selected for the Nakajimi Foundation Fellowship in 2013.</p>]]></content:encoded>
         <description><![CDATA[Speaker:�Kenji KawaguchiDate:�Tuesday, Oct 22 on 12:00 PM - 1:00 PMLocation:�Newell-Simon Hall 3305, CMUDetail: Abstract:�Deep learning and AI have provided high-impact data-driven methods in various applications. However, theoretical guarantees on deep learning and AI tend to provide too pessimistic insights with a gap from practical observations, because of hidden special properties of deep learning and AI problems. Identifying such special properties can provide novel theoretical insights, and is potentially helpful for designing methods and deriving better guarantees. In this talk, I will discuss special properties on non-convex optimization landscapes of deep neural networks and machine learning models, as well as their implications on gradient descent methods and the results on real-world applications based on theoretical insights.�� � Bio:�Kenji Kawaguchi is a Ph.D. candidate at Massachusetts Institute of Technology (MIT), advised by Prof. Leslie Pack Kaelbling. He received his M.S. in Electrical Engineering and Computer Science from MIT. His research interests span machine learning, deep learning, artificial intelligence, convex/nonconvex optimization and Bayesian optimization. His research has been cited widely in academia and used in classes. He was invited to speak at the 2019 International Congress on Industrial and Applied Mathematics Minisymposium on Theoretical Foundations of Deep Learning. In 2018, he was invited for a summer research visit at Microsoft Research in Redmond. He was awarded the Funai Overseas Scholarship in 2014 and was selected for the Nakajimi Foundation Fellowship in 2013.]]></description>
         <author>bmaneesh</author>
      </item>
   </channel>
</rss>